{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import viridis\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import pytorch_lightning\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(\"../src\"))\n",
    "\n",
    "from src.model import SpatiotemporalLightningModule, torch_rmse\n",
    "from src.util import NumpyDataset, to_np, to_item"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "Global seed set to 1\n",
      "Global seed set to 1\n",
      "Global seed set to 5\n",
      "Global seed set to 4\n",
      "Global seed set to 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "((104, 11, 7, 29, 59), (104, 1, 29, 59))"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dictionary with all data\n",
    "with open(\"subx/all_data.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "# prepare data\n",
    "args = argparse.Namespace(seed=1, n_train=731, n_val=104, batch_size=104)\n",
    "x, y, rand_inds = data[\"x\"], data[\"y\"], data[\"rand_inds\"]\n",
    "x = x[rand_inds[:, args.seed]]\n",
    "y = y[rand_inds[:, args.seed]]\n",
    "x = np.log(x + 1)\n",
    "mu_x, sigma_x = np.nanmean(x[:args.n_train + args.n_val]), np.nanstd(x[:args.n_train + args.n_val])\n",
    "x = (x - mu_x) / sigma_x\n",
    "\n",
    "# keep only test set data\n",
    "x, y = x[args.n_train + args.n_val:], y[args.n_train + args.n_val:]\n",
    "test_dataset = NumpyDataset(x, y)\n",
    "\n",
    "# load models trained on seed 1\n",
    "st_modules = {\n",
    "    \"b-l\": SpatiotemporalLightningModule.load_from_checkpoint(\"subx_models/b-l-1.ckpt\"),\n",
    "    \"b-l-g-f\": SpatiotemporalLightningModule.load_from_checkpoint(\"subx_models/b-l-g-f-1.ckpt\"),\n",
    "    \"b-l-g-v\": SpatiotemporalLightningModule.load_from_checkpoint(\"subx_models/b-l-g-v-1.ckpt\"),\n",
    "    \"d-cnn\": SpatiotemporalLightningModule.load_from_checkpoint(\"subx_models/d-cnn-5.ckpt\"),\n",
    "    \"vandal\": SpatiotemporalLightningModule.load_from_checkpoint(\"subx_models/vandal-4.ckpt\"),\n",
    "    \"ding\": SpatiotemporalLightningModule.load_from_checkpoint(\"subx_models/ding-1.ckpt\")\n",
    "}\n",
    "\n",
    "x.shape, y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Predict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating b-l\n",
      "Evaluating b-l-g-f\n",
      "Evaluating b-l-g-v\n",
      "Evaluating d-cnn\n",
      "Evaluating vandal\n",
      "Evaluating ding\n",
      "Evaluating mean\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "threshes = None\n",
    "\n",
    "for name, st_module in st_modules.items():\n",
    "    print(f\"Evaluating {name}\")\n",
    "    st_module.st_model.eval()\n",
    "    st_module.st_model.type(torch.FloatTensor)\n",
    "    x = torch.from_numpy(test_dataset.x).type(torch.FloatTensor)\n",
    "    y = torch.from_numpy(test_dataset.y).type(torch.FloatTensor)\n",
    "\n",
    "    # choose threshold\n",
    "    if st_module.st_model.variable_thresh:\n",
    "        # fix threshold at test time and augment predictors\n",
    "        t = np.nanquantile(to_np(y), st_module.st_model.quantile)\n",
    "        threshes = torch.ones_like(y) * t\n",
    "        x = torch.cat([x, threshes[:, np.newaxis].repeat(1, 1, x.shape[2], 1, 1)], axis=1)\n",
    "    else:\n",
    "        # generate fixed threshold but do not augment predictors\n",
    "        t = np.nanquantile(to_np(y), st_module.st_model.quantile)\n",
    "        threshes = torch.ones_like(y) * t\n",
    "\n",
    "    # apply appropriate forward pass (logic for each model type is handled in forward() definition\n",
    "    pred = st_module.st_model(x, threshes, test=True)\n",
    "    predictions[name] = pred\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "([tensor(6264.), tensor(133573.), tensor(38107.)],\n [tensor(0.0352), tensor(0.7506), tensor(0.2142)])"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extreme_mask = torch.where(y > threshes, 1.0, np.float32(np.nan))\n",
    "zero_mask = torch.where(y == 0, 1.0, np.float32(np.nan))\n",
    "moderate_mask = torch.where(torch.logical_and(torch.isnan(extreme_mask), torch.isnan(zero_mask)), 1.0, np.nan)\n",
    "n_extreme = torch.nansum(extreme_mask)\n",
    "n_zero = torch.nansum(zero_mask)\n",
    "n_moderate = torch.nansum(moderate_mask)\n",
    "p_extreme = n_extreme / (n_extreme + n_zero + n_moderate)\n",
    "p_zero = n_zero / (n_extreme + n_zero + n_moderate)\n",
    "p_moderate = n_moderate / (n_extreme + n_zero + n_moderate)\n",
    "[n_zero, n_moderate, n_extreme], [p_zero, p_moderate, p_extreme]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioning b-l\n",
      "Partitioning b-l-g-f\n",
      "Partitioning b-l-g-v\n",
      "Partitioning d-cnn\n",
      "Partitioning vandal\n",
      "Partitioning ding\n",
      "Partitioning mean\n"
     ]
    }
   ],
   "source": [
    "extreme_predictions = {}\n",
    "zero_predictions = {}\n",
    "moderate_predictions = {}\n",
    "for name, pred in predictions.items():\n",
    "# for name, pred in [(\"d-cnn\", predictions[\"d-cnn\"])]:\n",
    "    print(f\"Partitioning {name}\")\n",
    "    if isinstance(pred, tuple):\n",
    "        extreme_pred = []\n",
    "        zero_pred = []\n",
    "        moderate_pred = []\n",
    "        for p in pred:\n",
    "            extreme_pred.append(extreme_mask.unsqueeze(1) * p)\n",
    "            zero_pred.append(zero_mask.unsqueeze(1) * p)\n",
    "            moderate_pred.append(moderate_mask.unsqueeze(1) * p)\n",
    "        extreme_pred = tuple(extreme_pred)\n",
    "        zero_pred = tuple(zero_pred)\n",
    "        moderate_pred = tuple(moderate_pred)\n",
    "    else:\n",
    "        extreme_pred = extreme_mask * pred\n",
    "        zero_pred = zero_mask * pred\n",
    "        moderate_pred = moderate_mask * pred\n",
    "    extreme_predictions[name] = extreme_pred\n",
    "    zero_predictions[name] = zero_pred\n",
    "    moderate_predictions[name] = moderate_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating b-l\n",
      "nan here\n",
      "nan here\n",
      "nan here\n",
      "Evaluating b-l-g-f\n",
      "nan here\n",
      "nan here\n",
      "nan here\n",
      "Evaluating b-l-g-v\n",
      "nan here\n",
      "nan here\n",
      "nan here\n",
      "Evaluating d-cnn\n",
      "Evaluating vandal\n",
      "nan here\n",
      "nan here\n",
      "nan here\n",
      "Evaluating ding\n",
      "Evaluating mean\n"
     ]
    },
    {
     "data": {
      "text/plain": "      name  zero_nll_loss  zero_rmse_loss  moderate_nll_loss  \\\n0      b-l       3.084146        2.275355          -0.653544   \n1  b-l-g-f       3.743166        2.119304          -2.068084   \n2  b-l-g-v       1.985108        2.096633          -2.178074   \n3    d-cnn       0.000000        2.147511           0.000000   \n4   vandal       0.657426        2.518800           2.779107   \n5     ding       0.153669        2.409375           0.155168   \n6     mean       0.000000        0.606222           0.000000   \n\n   moderate_rmse_loss  extreme_nll_loss  extreme_rmse_loss  \n0            1.917129          3.936596           5.561101  \n1            1.801627          3.393848           5.470887  \n2            1.853699          5.346167           5.498644  \n3            1.920702          0.000000           5.351133  \n4            1.971399          4.337051           7.000628  \n5            1.913268          0.241759           5.649497  \n6            0.650063          0.000000           6.947647  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>zero_nll_loss</th>\n      <th>zero_rmse_loss</th>\n      <th>moderate_nll_loss</th>\n      <th>moderate_rmse_loss</th>\n      <th>extreme_nll_loss</th>\n      <th>extreme_rmse_loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b-l</td>\n      <td>3.084146</td>\n      <td>2.275355</td>\n      <td>-0.653544</td>\n      <td>1.917129</td>\n      <td>3.936596</td>\n      <td>5.561101</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b-l-g-f</td>\n      <td>3.743166</td>\n      <td>2.119304</td>\n      <td>-2.068084</td>\n      <td>1.801627</td>\n      <td>3.393848</td>\n      <td>5.470887</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b-l-g-v</td>\n      <td>1.985108</td>\n      <td>2.096633</td>\n      <td>-2.178074</td>\n      <td>1.853699</td>\n      <td>5.346167</td>\n      <td>5.498644</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>d-cnn</td>\n      <td>0.000000</td>\n      <td>2.147511</td>\n      <td>0.000000</td>\n      <td>1.920702</td>\n      <td>0.000000</td>\n      <td>5.351133</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>vandal</td>\n      <td>0.657426</td>\n      <td>2.518800</td>\n      <td>2.779107</td>\n      <td>1.971399</td>\n      <td>4.337051</td>\n      <td>7.000628</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ding</td>\n      <td>0.153669</td>\n      <td>2.409375</td>\n      <td>0.155168</td>\n      <td>1.913268</td>\n      <td>0.241759</td>\n      <td>5.649497</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>mean</td>\n      <td>0.000000</td>\n      <td>0.606222</td>\n      <td>0.000000</td>\n      <td>0.650063</td>\n      <td>0.000000</td>\n      <td>6.947647</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = []\n",
    "for name in predictions.keys():\n",
    "    print(f\"Evaluating {name}\")\n",
    "    zero_loss, zero_nll_loss, zero_rmse_loss = to_item(st_modules[name].st_model.compute_losses(pred=zero_predictions[name], y=zero_mask * y, threshes=threshes))\n",
    "    moderate_loss, moderate_nll_loss, moderate_rmse_loss = to_item(st_modules[name].st_model.compute_losses(pred=moderate_predictions[name], y=moderate_mask * y, threshes=threshes))\n",
    "    extreme_loss, extreme_nll_loss, extreme_rmse_loss = to_item(st_modules[name].st_model.compute_losses(pred=extreme_predictions[name], y=extreme_mask * y, threshes=threshes))\n",
    "    losses.append({\n",
    "        \"name\": name,\n",
    "        \"zero_nll_loss\": zero_nll_loss, \"zero_rmse_loss\": zero_rmse_loss,\n",
    "        \"moderate_nll_loss\": moderate_nll_loss, \"moderate_rmse_loss\": moderate_rmse_loss,\n",
    "        \"extreme_nll_loss\": extreme_nll_loss, \"extreme_rmse_loss\": extreme_rmse_loss,\n",
    "        \"p_zero\": p_zero, \"p_moderate\": p_moderate, \"p_extreme\": p_extreme\n",
    "    })\n",
    "\n",
    "losses_df = pd.DataFrame(losses)\n",
    "losses_df.to_csv(\"results/subx_partition.csv\")\n",
    "losses_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}